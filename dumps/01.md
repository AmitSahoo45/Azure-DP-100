1. You are planning to host practical training to acquaint staff with Docker for Windows.
Staff devices must support the installation of Docker.
Which of the following are requirements for this installation? Answer by dragging the correct options from the list to the answer area.


Answer:
a. 4GB of System RAM
b. BIOS enabled virtualization
c. Windows 10 64 bit

----

2. __ - __ - __ is required for a Deep Learning Virtual Machine (DLVM) to support Compute Unified Device Architecture (CUDA) computations.
a. SSD
b. FGPA
c. GPU
d. Power BI

<details> 
<summary>Answer</summary>
GPU - A Deep Learning Virtual Machine is a pre-configured environment for deep learning using GPU instances.
</details>

----

3. You need to implement a Data Science Virtual Machine (DSVM) that supports the Caffe2 deep learning framework.
Which of the following DSVM should you create?
A. Windows Server 2012 DSVM
B. Windows Server 2016 DSVM
C. Ubuntu 16.04 DSVM
D. CentOS 7.4 DSVM

<details> 
<summary>Answer</summary>
C. Ubuntu 16.04 DSVM
</details>

----

4. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.
You are preparing to create a virtual machine that has the necessary tools built into it.
You need to make use of the correct virtual machine type.
Recommendation: You make use of a Geo AI Data Science Virtual Machine (Geo-DSVM) Windows edition.
Will the requirements be satisfied?
A. Yes
B. No

<details> 
<summary>Answer</summary>
No
</details>

----

6. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.
You are preparing to create a virtual machine that has the necessary tools built into it.
You need to make use of the correct virtual machine type.
Recommendation: You make use of a Deep Learning Virtual Machine (DLVM) Windows edition.
Will the requirements be satisfied?
A. Yes
B. No

<details> 
<summary>Answer</summary>
Yes
</details>

----

7. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You have been tasked with employing a machine learning model, which makes use of a PostgreSQL database and needs GPU processing, to forecast prices.
You are preparing to create a virtual machine that has the necessary tools built into it.
You need to make use of the correct virtual machine type.
Recommendation: You make use of a Data Science Virtual Machine (DSVM) Windows edition.
Will the requirements be satisfied?
A. Yes
B. No

<details> 
<summary>Answer</summary>
No, the requirements will not be satisfied.
</details>

----

8. You have been tasked with moving data into Azure Blob Storage for the purpose of supporting Azure Machine Learning.
Which of the following can be used to complete your task? Answer by dragging the correct options from the list to the answer area.

options: 
AzCopy
Bulk Copy Program (BCP)
SSIS
Azure storage explorer
Bulk Insert SQL Query

<details> 
<summary>Answer</summary>
AzCopy, SSIS, Azure storage explorer
</details>

----

9. To move a large dataset from Azure Machine Learning Studio to a Weka Environment, the data must be converted to the __ - __ - __ format. 
a. CSV
b. DOCX
c. ARFF
d. TXT

<details> 
<summary>Answer</summary>
ARFF - Use the Convert to ARFF module in Azure Machine Learning Studio, to convert datasets and results in Azure Machine Learning to the attribute-relation file format used by the Weka toolset. This format is known as ARFF.
The ARFF data specification for Weka supports multiple machine learning tasks, including data preprocessing, classification, and feature selection. In this format, data is organized by entities and their attributes, and is contained in a single text file.
</details>

----

10. You have been tasked with designing a deep learning model, which accommodates the most recent edition of Python, to recognize language.
You have to include a suitable deep learning framework in the Data Science Virtual Machine (DSVM).
Which of the following actions should you take?
A. You should consider including Rattle.
B. You should consider including TensorFlow.
C. You should consider including Theano.
D. You should consider including Chainer.

<details> 
<summary>Answer</summary>
B. You should consider including TensorFlow.
</details>

----

11. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You have been tasked with evaluating your model on a partial data sample via k-fold cross-validation.
You have already configured a k parameter as the number of splits. You now have to configure the k parameter for the cross-validation with the usual value choice.
Recommendation: You configure the use of the value k=3.
Will the requirements be satisfied?
A. Yes
B. No

<details> 
<summary>Answer</summary>
No
</details>

----

12. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.

You have been tasked with evaluating your model on a partial data sample via k-fold cross-validation.
You have already configured a k parameter as the number of splits. You now have to configure the k parameter for the cross-validation with the usual value choice.

Solution: You configure the use of the value k=10.
Will the requirements be satisfied?

A. Yes
B. No

<details> 
<summary>Answer</summary>
Yes
Leave One Out (LOO) cross-validation
Setting K = n (the number of observations) yields n-fold and is called leave-one out cross-validation (LOO), a special case of the K-fold approach.
LOO CV is sometimes useful but typically doesn't shake up the data enough. The estimates from each fold are highly correlated and hence their average can have high variance.
This is why the usual choice is K=5 or 10. It provides a good compromise for the bias-variancetradeoff.
</details>

----

13. You construct a machine learning experiment via Azure Machine Learning Studio.
You would like to split data into two separate datasets.
Which of the following actions should you take?

a. You should make use of the Split Data module.
b. You should make use of the Group Categorical Values module.
c. You should make use of the Clip Values module.
d. You should make use of the Group Data into Bins module.

<details>
<summary>Answer</summary>
d. You should make use of the Group Data into Bins module.
The Group Data into Bins module supports multiple options for binning data. You can customize how the bin edges are set and how values are apportioned into the bins.
</details>

----

14. You have been tasked with creating a new Azure pipeline via the Machine Learning designer.
You have to makes sure that the pipeline trains a model using data in a comma-separated values (CSV) file that is published on a website. A dataset for the file for this file does not exist.
Data from the CSV file must be ingested into the designer pipeline with the least amount of administrative effort as possible.
Which of the following actions should you take?

a. You should make use of the Convert to TXT module.
b. You should add the Copy Data object to the pipeline.
c. You should add the Import Data object to the pipeline.
d. You should add the Dataset object to the pipeline.

<details>
<summary>Answer</summary>
D
Explanation:
The preferred way to provide data to a pipeline is a Dataset object. The Dataset object points to data that lives in or is accessible from a datastore or at a Web
URL. The Dataset class is abstract, so you will create an instance of either a FileDataset (referring to one or more files) or a TabularDataset that's created by from one or more files with delimited columns of data.
</details>

----

15. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.

You plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.

Solution: You make use of the Replace with median option.
Will the requirements be satisfied?

Yes
No

<details>
<summary>Answer</summary>
Yes, the requirements will be satisfied.

Here's why:

Handling Missing Values: The Clean Missing Data module in Azure Machine Learning Studio is specifically designed to detect and handle missing values in your dataset. Using the "Replace with median" option effectively fills in missing numerical values with the median of the existing data, which is a robust measure against outliers compared to the mean.

Appropriate Imputation Method: Replacing missing values with the median is a common and acceptable practice, especially when dealing with skewed data or outliers. It helps in maintaining the central tendency of the data without being influenced by extreme values.

Requirement Alignment: Your requirement is to detect and fix null and missing values in the dataset to proceed with creating a machine learning model. Using this method satisfies that requirement by providing a systematic way to handle missing data.

Ease of Implementation: The Clean Missing Data module simplifies the process, and selecting "Replace with median" requires minimal configuration, ensuring that the dataset is prepared efficiently for model training.
</details>

----

16. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.

You plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.

Solution: You make use of the Custom substitution value option.
Will the requirements be satisfied?

Yes
No

<details>
<summary>Answer</summary>
Yes, the requirements will be satisfied.

By using the "Custom substitution value" option in the Clean Missing Data module, you effectively detect and fix the null and missing values in your dataset, satisfying the requirements for preparing your machine learning model.
</details>

----

17. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You are in the process of creating a machine learning model. Your dataset includes rows with null and missing values.

You plan to make use of the Clean Missing Data module in Azure Machine Learning Studio to detect and fix the null and missing values in the dataset.

Solution: You make use of the Remove entire row option.
Will the requirements be satisfied?

Yes
No

<details>
<summary>Answer</summary>
Yes, the requirements will be satisfied.

By using the "Remove entire row" option in the Clean Missing Data module, you effectively detect and fix the null and missing values by eliminating incomplete data from your dataset. This satisfies the requirements for preparing your machine learning model, provided that the data loss does not adversely affect your model's performance.
</details>

----

18. You need to consider the underlined segment to establish whether it is accurate.
To transform a categorical feature into a binary indicator, you should make use of the Clean Missing Data module.
Select `No adjustment required` if the underlined segment is accurate. If the underlined segment is inaccurate, select the accurate option.

No adjustment required.
Convert to Indicator Values
Apply SQL Transformation
Group Categorical Values

<details>
<summary>Answer</summary>
Convert to Indicator Values
Explanation:
Use the Convert to Indicator Values module in Azure Machine Learning Studio. The purpose of this module is to convert columns that contain categorical values into a series of binary indicator columns that can more easily be used as features in a machine learning model.
</details>

----

19. You need to consider the underlined segment to establish whether it is accurate.
To improve the amount of low incidence cases in a dataset, you should make use of the SMOTE module.
Select `No adjustment required` if the underlined segment is accurate. If the underlined segment is inaccurate, select the accurate option.

No adjustment required.
Remove Duplicate Rows
Join Data
Edit Metadata

<details>
<summary>Answer</summary>
No adjustment required

Explanation:
Use the SMOTE module in Azure Machine Learning Studio to increase the number of underrepresented cases in a dataset used for machine learning. SMOTE is a better way of increasing the number of rare cases than simply duplicating existing cases.
</details>

----

20. HOTSPOT (Drag and Drop is not supported)
You need to consider the underlined segment to establish whether it is accurate.
Hot Area:

The __ - __ - __ visualization can be used to reveal outliers in your data. 

a. Venn Diagram
b. Box Plot
c. Gradient Descent
d. Violin Plot

<details>
<summary>Answer</summary>
b. Box Plot

Explanation:
The box-plot algorithm can be used to display outliers.
</details>

----

21. You are planning to host practical training to acquaint learners with data visualization creation using Python. Learner devices are able to connect to the internet.

Learner devices are currently NOT configured for Python development. Also, learners are unable to install software on their devices as they lack administrator permissions. Furthermore, they are unable to access Azure subscriptions.

It is imperative that learners are able to execute Python-based data visualization code.
Which of the following actions should you take?

You should consider configuring the use of Azure Container Instance.
You should consider configuring the use of Azure BatchAI.
You should consider configuring the use of Azure Notebooks.
You should consider configuring the use of Azure Kubernetes Service.

<details>
<summary>Answer</summary>
C. You should consider configuring the use of Azure Notebooks.

Explanation:
https://notebooks.azure.com/
<details>

----

22. __ - __ - __ is a data cleaning option of the Clean Missing Data module that doesn't require predictors for each column.
a. Probabilistic PCA
b. Median 
c. SMOTE
d. Custom substitution value

<details>
<summary>Answer</summary>
b. Median

The "Median" is a data cleaning option in the Clean Missing Data module of Azure Machine Learning Studio that replaces missing values with the median of the existing values in each column. This method does not require predictors for each column because it uses a simple statistical measure computed from the column's own data.
</details>

----

23. You have recently concluded the construction of a binary classification machine learning model.
You are currently assessing the model. You want to make use of a visualization that allows for precision to be used as the measurement for the assessment.
Which of the following actions should you take?

You should consider using Venn diagram visualization.
You should consider using Receiver Operating Characteristic (ROC) curve visualization.
You should consider using Box plot visualization.
You should consider using the Binary classification confusion matrix visualization.

<details>
<summary>Answer</summary>
B. You should consider using Receiver Operating Characteristic (ROC) curve visualization.

Explanation:
The Receiver Operating Characteristic (ROC) curve is a graphical representation that allows you to assess the performance of a binary classification model using precision as one of the key metrics. The ROC curve plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings, providing a comprehensive view of the model's performance across different classification thresholds.

The ROC curve is particularly useful for evaluating the trade-off between true positive rate and false positive rate, and it can help you determine the optimal threshold for your model based on your specific requirements.
</details>

----

24. This question is included in a number of questions that depicts the identical set-up. However, every question has a distinctive result. Establish if the recommendation satisfies the requirements.
You have been tasked with evaluating your model on a partial data sample via k-fold cross-validation.
You have already configured a k parameter as the number of splits. You now have to configure the k parameter for the cross-validation with the usual value choice.
Solution: You configure the use of the value k=1.
Will the requirements be satisfied?

Yes
No

<details>
<summary>Answer</summary>
No, the requirements will not be satisfied.

Explanation:
Setting k = 1 for k-fold cross-validation does not satisfy the requirement of evaluating the model on a partial data sample.
To meet the requirements, you should choose a typical value for k, such as 5 or 10, to properly perform k-fold cross-validation and evaluate your model effectively.
</details>